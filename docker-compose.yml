version: "3.7"
services:
  zookeeper:
    restart: always
    image: docker.io/bitnami/zookeeper:3.8
    ports:
      - "2181:2181"
    volumes:
      - "zookeeper-volume:/bitnami"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    healthcheck:
      test: ["CMD", "echo", "ruok"]
      interval: 5s
      timeout: 2s
      retries: 3

  kafka:
    restart: always
    image: docker.io/bitnami/kafka:3.3
    ports:
      - "9093:9093"
    volumes:
      - "kafka-volume:/bitnami"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_LISTENERS=CLIENT://:9092,EXTERNAL://:9093
      - KAFKA_ADVERTISED_LISTENERS=CLIENT://kafka:9092,EXTERNAL://host.docker.internal:9093
      - KAFKA_INTER_BROKER_LISTENER_NAME=CLIENT
    depends_on:
      zookeeper:
        condition: service_healthy

  selenium-chrome:
    image: seleniarm/standalone-chromium  # ARM-compatible image
    container_name: selenium-chrome
    ports:
      - "4444:4444"
    volumes:
      - /dev/shm:/dev/shm
    restart: always

  vectordb:
    # image: ghcr.io/chroma-core/chroma:0.5.2  # Image tag: https://github.com/chroma-core/chroma/releases
    # image: ghcr.io/chroma-core/chroma:0.5.3
    build:
      context: .
      dockerfile: Dockerfile
    command: uvicorn chromadb.app:app --workers 1 --host 0.0.0.0 --port 8800 --proxy-headers --timeout-keep-alive 30 
    container_name: chroma_docker
    ports:
      - 8800:8800
    env_file:
      - ./.env
    volumes:
      - ./chroma_configs/my_db:/chroma/my_db
      #- ./my_config:/chroma/my_config

  elasticsearch:
    restart: always
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - "elasticsearch-volume:/usr/share/elasticsearch/data"

  kibana:
    restart: always
    image: docker.elastic.co/kibana/kibana:8.9.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  streamlit_service:
    build:
      context: .
    command: streamlit run app.py --server.port 8501 --server.address 0.0.0.0
    ports:
      - "8501:8501"
    working_dir: /app/src  # Ensure you're in the correct directory
    depends_on:
      - kafka
      - vectordb

  submit_service:
    build:
      context: .
    command: ["bash", "submit.sh"]
    working_dir: /app/src
    depends_on:
      - kafka

  consumer_service:
    build:
      context: .
    command: ["python", "codeKafka/consumer_elastic.py"]
    working_dir: /app/src
    depends_on:
      - kafka

volumes:
  kafka-volume:
  zookeeper-volume:
  chromadb-volume:
  elasticsearch-volume: